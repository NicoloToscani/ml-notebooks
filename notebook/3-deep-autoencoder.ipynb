{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Autoencoder\n",
    "\n",
    "784 -> 128 -> 64 > 32 > 64 > 128 -> 784\n",
    "\n",
    "![](img/autoencoder_schema.jpg)\n",
    "\n",
    "`Warning: since the dataset is quite easy there will not be major loss differences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# ENCODER\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "# DECODER\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# MODEL\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite easy, right? (If you want to do the same thing using TensorFlow directly it would take much more code)\n",
    "\n",
    "Now we have to compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adagrad', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we need data, rescaled between 0 and 1, and reshaped in a 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to train using the `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2629 - val_loss: 0.2626\n",
      "Epoch 2/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2629 - val_loss: 0.2625\n",
      "Epoch 3/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2629 - val_loss: 0.2625\n",
      "Epoch 4/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2628 - val_loss: 0.2625\n",
      "Epoch 5/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2628 - val_loss: 0.2624\n",
      "Epoch 6/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2628 - val_loss: 0.2624\n",
      "Epoch 7/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2627 - val_loss: 0.2624\n",
      "Epoch 8/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2627 - val_loss: 0.2623\n",
      "Epoch 9/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2627 - val_loss: 0.2623\n",
      "Epoch 10/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2626 - val_loss: 0.2623\n",
      "Epoch 11/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2626 - val_loss: 0.2622\n",
      "Epoch 12/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2626 - val_loss: 0.2622\n",
      "Epoch 13/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.2622\n",
      "Epoch 14/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.2622\n",
      "Epoch 15/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.2621\n",
      "Epoch 16/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.2621\n",
      "Epoch 17/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2624 - val_loss: 0.2621\n",
      "Epoch 18/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2624 - val_loss: 0.2620\n",
      "Epoch 19/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2624 - val_loss: 0.2620\n",
      "Epoch 20/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2623 - val_loss: 0.2620\n",
      "Epoch 21/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2623 - val_loss: 0.2619\n",
      "Epoch 22/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2623 - val_loss: 0.2619\n",
      "Epoch 23/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2622 - val_loss: 0.2619\n",
      "Epoch 24/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2622 - val_loss: 0.2618\n",
      "Epoch 25/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2622 - val_loss: 0.2618\n",
      "Epoch 26/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2621 - val_loss: 0.2618\n",
      "Epoch 27/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2621 - val_loss: 0.2617\n",
      "Epoch 28/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2621 - val_loss: 0.2617\n",
      "Epoch 29/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2620 - val_loss: 0.2617\n",
      "Epoch 30/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2620 - val_loss: 0.2617\n",
      "Epoch 31/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2620 - val_loss: 0.2616\n",
      "Epoch 32/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2620 - val_loss: 0.2616\n",
      "Epoch 33/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2619 - val_loss: 0.2616\n",
      "Epoch 34/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2619 - val_loss: 0.2615\n",
      "Epoch 35/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2619 - val_loss: 0.2615\n",
      "Epoch 36/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2618 - val_loss: 0.2615\n",
      "Epoch 37/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2618 - val_loss: 0.2614\n",
      "Epoch 38/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2618 - val_loss: 0.2614\n",
      "Epoch 39/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2617 - val_loss: 0.2614\n",
      "Epoch 40/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2617 - val_loss: 0.2613\n",
      "Epoch 41/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2617 - val_loss: 0.2613\n",
      "Epoch 42/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2616 - val_loss: 0.2613\n",
      "Epoch 43/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2616 - val_loss: 0.2612\n",
      "Epoch 44/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2616 - val_loss: 0.2612\n",
      "Epoch 45/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2615 - val_loss: 0.2612\n",
      "Epoch 46/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2615 - val_loss: 0.2612\n",
      "Epoch 47/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2615 - val_loss: 0.2611\n",
      "Epoch 48/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2614 - val_loss: 0.2611\n",
      "Epoch 49/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2614 - val_loss: 0.2611\n",
      "Epoch 50/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2614 - val_loss: 0.2610\n",
      "Epoch 51/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2614 - val_loss: 0.2610\n",
      "Epoch 52/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.2610\n",
      "Epoch 53/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.2609\n",
      "Epoch 54/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.2609\n",
      "Epoch 55/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2612 - val_loss: 0.2609\n",
      "Epoch 56/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2612 - val_loss: 0.2608\n",
      "Epoch 57/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2612 - val_loss: 0.2608\n",
      "Epoch 58/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2611 - val_loss: 0.2608\n",
      "Epoch 59/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2611 - val_loss: 0.2607\n",
      "Epoch 60/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2611 - val_loss: 0.2607\n",
      "Epoch 61/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2610 - val_loss: 0.2607\n",
      "Epoch 62/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2610 - val_loss: 0.2606\n",
      "Epoch 63/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2610 - val_loss: 0.2606\n",
      "Epoch 64/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2609 - val_loss: 0.2606\n",
      "Epoch 65/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2609 - val_loss: 0.2606\n",
      "Epoch 66/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2609 - val_loss: 0.2605\n",
      "Epoch 67/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2609 - val_loss: 0.2605\n",
      "Epoch 68/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2608 - val_loss: 0.2605\n",
      "Epoch 69/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2608 - val_loss: 0.2604\n",
      "Epoch 70/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2608 - val_loss: 0.2604\n",
      "Epoch 71/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2607 - val_loss: 0.2604\n",
      "Epoch 72/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2607 - val_loss: 0.2603\n",
      "Epoch 73/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2607 - val_loss: 0.2603\n",
      "Epoch 74/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2606 - val_loss: 0.2603\n",
      "Epoch 75/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2606 - val_loss: 0.2602\n",
      "Epoch 76/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2606 - val_loss: 0.2602\n",
      "Epoch 77/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2605 - val_loss: 0.2602\n",
      "Epoch 78/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2605 - val_loss: 0.2601\n",
      "Epoch 79/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2605 - val_loss: 0.2601\n",
      "Epoch 80/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2604 - val_loss: 0.2600\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2604 - val_loss: 0.2600\n",
      "Epoch 82/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2603 - val_loss: 0.2600\n",
      "Epoch 83/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2603 - val_loss: 0.2599\n",
      "Epoch 84/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2603 - val_loss: 0.2599\n",
      "Epoch 85/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2602 - val_loss: 0.2599\n",
      "Epoch 86/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2602 - val_loss: 0.2598\n",
      "Epoch 87/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2602 - val_loss: 0.2598\n",
      "Epoch 88/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2601 - val_loss: 0.2598\n",
      "Epoch 89/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2601 - val_loss: 0.2597\n",
      "Epoch 90/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2601 - val_loss: 0.2597\n",
      "Epoch 91/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2600 - val_loss: 0.2597\n",
      "Epoch 92/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2600 - val_loss: 0.2596\n",
      "Epoch 93/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2600 - val_loss: 0.2596\n",
      "Epoch 94/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2599 - val_loss: 0.2596\n",
      "Epoch 95/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2599 - val_loss: 0.2595\n",
      "Epoch 96/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2599 - val_loss: 0.2595\n",
      "Epoch 97/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2598 - val_loss: 0.2595\n",
      "Epoch 98/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2598 - val_loss: 0.2594\n",
      "Epoch 99/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2598 - val_loss: 0.2594\n",
      "Epoch 100/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2597 - val_loss: 0.2594\n",
      "Epoch 101/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2597 - val_loss: 0.2593\n",
      "Epoch 102/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2597 - val_loss: 0.2593\n",
      "Epoch 103/300\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2596 - val_loss: 0.2593\n",
      "Epoch 104/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2596 - val_loss: 0.2592\n",
      "Epoch 105/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2596 - val_loss: 0.2592\n",
      "Epoch 106/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2595 - val_loss: 0.2592\n",
      "Epoch 107/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2595 - val_loss: 0.2591\n",
      "Epoch 108/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2595 - val_loss: 0.2591\n",
      "Epoch 109/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2594 - val_loss: 0.2591\n",
      "Epoch 110/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2594 - val_loss: 0.2590\n",
      "Epoch 111/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2594 - val_loss: 0.2590\n",
      "Epoch 112/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2593 - val_loss: 0.2589\n",
      "Epoch 113/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2593 - val_loss: 0.2589\n",
      "Epoch 114/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2593 - val_loss: 0.2589\n",
      "Epoch 115/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2592 - val_loss: 0.2588\n",
      "Epoch 116/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2592 - val_loss: 0.2588\n",
      "Epoch 117/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2592 - val_loss: 0.2588\n",
      "Epoch 118/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2591 - val_loss: 0.2587\n",
      "Epoch 119/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2591 - val_loss: 0.2587\n",
      "Epoch 120/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2591 - val_loss: 0.2587\n",
      "Epoch 121/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2590 - val_loss: 0.2586\n",
      "Epoch 122/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2590 - val_loss: 0.2586\n",
      "Epoch 123/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2590 - val_loss: 0.2586\n",
      "Epoch 124/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2589 - val_loss: 0.2585\n",
      "Epoch 125/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2589 - val_loss: 0.2585\n",
      "Epoch 126/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2589 - val_loss: 0.2585\n",
      "Epoch 127/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2588 - val_loss: 0.2584\n",
      "Epoch 128/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2588 - val_loss: 0.2584\n",
      "Epoch 129/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2587 - val_loss: 0.2583\n",
      "Epoch 130/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2587 - val_loss: 0.2583\n",
      "Epoch 131/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2587 - val_loss: 0.2583\n",
      "Epoch 132/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2586 - val_loss: 0.2582\n",
      "Epoch 133/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2586 - val_loss: 0.2582\n",
      "Epoch 134/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2586 - val_loss: 0.2582\n",
      "Epoch 135/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2585 - val_loss: 0.2581\n",
      "Epoch 136/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2585 - val_loss: 0.2581\n",
      "Epoch 137/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2585 - val_loss: 0.2581\n",
      "Epoch 138/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2584 - val_loss: 0.2580\n",
      "Epoch 139/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2584 - val_loss: 0.2580\n",
      "Epoch 140/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2584 - val_loss: 0.2579\n",
      "Epoch 141/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2583 - val_loss: 0.2579\n",
      "Epoch 142/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2583 - val_loss: 0.2579\n",
      "Epoch 143/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2582 - val_loss: 0.2578\n",
      "Epoch 144/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2582 - val_loss: 0.2578\n",
      "Epoch 145/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2582 - val_loss: 0.2578\n",
      "Epoch 146/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2581 - val_loss: 0.2577\n",
      "Epoch 147/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2581 - val_loss: 0.2577\n",
      "Epoch 148/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2581 - val_loss: 0.2577\n",
      "Epoch 149/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2580 - val_loss: 0.2576\n",
      "Epoch 150/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2580 - val_loss: 0.2576\n",
      "Epoch 151/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2579 - val_loss: 0.2575\n",
      "Epoch 152/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2579 - val_loss: 0.2575\n",
      "Epoch 153/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2579 - val_loss: 0.2575\n",
      "Epoch 154/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2578 - val_loss: 0.2574\n",
      "Epoch 155/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2578 - val_loss: 0.2574\n",
      "Epoch 156/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2578 - val_loss: 0.2573\n",
      "Epoch 157/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2577 - val_loss: 0.2573\n",
      "Epoch 158/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2577 - val_loss: 0.2573\n",
      "Epoch 159/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2576 - val_loss: 0.2572\n",
      "Epoch 160/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2576 - val_loss: 0.2572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2576 - val_loss: 0.2571\n",
      "Epoch 162/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2575 - val_loss: 0.2571\n",
      "Epoch 163/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2575 - val_loss: 0.2571\n",
      "Epoch 164/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2574 - val_loss: 0.2570\n",
      "Epoch 165/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2574 - val_loss: 0.2570\n",
      "Epoch 166/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2574 - val_loss: 0.2569\n",
      "Epoch 167/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2573 - val_loss: 0.2569\n",
      "Epoch 168/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2573 - val_loss: 0.2569\n",
      "Epoch 169/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2572 - val_loss: 0.2568\n",
      "Epoch 170/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2572 - val_loss: 0.2568\n",
      "Epoch 171/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2572 - val_loss: 0.2567\n",
      "Epoch 172/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2571 - val_loss: 0.2567\n",
      "Epoch 173/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2571 - val_loss: 0.2567\n",
      "Epoch 174/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2570 - val_loss: 0.2566\n",
      "Epoch 175/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2570 - val_loss: 0.2566\n",
      "Epoch 176/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2570 - val_loss: 0.2565\n",
      "Epoch 177/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2569 - val_loss: 0.2565\n",
      "Epoch 178/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2569 - val_loss: 0.2564\n",
      "Epoch 179/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2568 - val_loss: 0.2564\n",
      "Epoch 180/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2568 - val_loss: 0.2564\n",
      "Epoch 181/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2567 - val_loss: 0.2563\n",
      "Epoch 182/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2567 - val_loss: 0.2563\n",
      "Epoch 183/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2567 - val_loss: 0.2562\n",
      "Epoch 184/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2566 - val_loss: 0.2562\n",
      "Epoch 185/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2566 - val_loss: 0.2561\n",
      "Epoch 186/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2565 - val_loss: 0.2561\n",
      "Epoch 187/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2565 - val_loss: 0.2560\n",
      "Epoch 188/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2564 - val_loss: 0.2560\n",
      "Epoch 189/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2564 - val_loss: 0.2560\n",
      "Epoch 190/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2564 - val_loss: 0.2559\n",
      "Epoch 191/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2563 - val_loss: 0.2559\n",
      "Epoch 192/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2563 - val_loss: 0.2558\n",
      "Epoch 193/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2562 - val_loss: 0.2558\n",
      "Epoch 194/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2562 - val_loss: 0.2557\n",
      "Epoch 195/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2561 - val_loss: 0.2557\n",
      "Epoch 196/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2561 - val_loss: 0.2556\n",
      "Epoch 197/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2560 - val_loss: 0.2556\n",
      "Epoch 198/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2560 - val_loss: 0.2555\n",
      "Epoch 199/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2560 - val_loss: 0.2555\n",
      "Epoch 200/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2559 - val_loss: 0.2554\n",
      "Epoch 201/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2559 - val_loss: 0.2554\n",
      "Epoch 202/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2558 - val_loss: 0.2553\n",
      "Epoch 203/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2558 - val_loss: 0.2553\n",
      "Epoch 204/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2557 - val_loss: 0.2553\n",
      "Epoch 205/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2557 - val_loss: 0.2552\n",
      "Epoch 206/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2556 - val_loss: 0.2552\n",
      "Epoch 207/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2556 - val_loss: 0.2551\n",
      "Epoch 208/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2555 - val_loss: 0.2551\n",
      "Epoch 209/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2555 - val_loss: 0.2550\n",
      "Epoch 210/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2554 - val_loss: 0.2550\n",
      "Epoch 211/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2554 - val_loss: 0.2549\n",
      "Epoch 212/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2553 - val_loss: 0.2549\n",
      "Epoch 213/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2553 - val_loss: 0.2548\n",
      "Epoch 214/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2552 - val_loss: 0.2548\n",
      "Epoch 215/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2552 - val_loss: 0.2547\n",
      "Epoch 216/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2551 - val_loss: 0.2547\n",
      "Epoch 217/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2551 - val_loss: 0.2546\n",
      "Epoch 218/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2550 - val_loss: 0.2545\n",
      "Epoch 219/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2550 - val_loss: 0.2545\n",
      "Epoch 220/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2549 - val_loss: 0.2544\n",
      "Epoch 221/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2549 - val_loss: 0.2544\n",
      "Epoch 222/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2548 - val_loss: 0.2543\n",
      "Epoch 223/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2548 - val_loss: 0.2543\n",
      "Epoch 224/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2547 - val_loss: 0.2542\n",
      "Epoch 225/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2547 - val_loss: 0.2542\n",
      "Epoch 226/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2546 - val_loss: 0.2541\n",
      "Epoch 227/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2546 - val_loss: 0.2541\n",
      "Epoch 228/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2545 - val_loss: 0.2540\n",
      "Epoch 229/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2545 - val_loss: 0.2540\n",
      "Epoch 230/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2544 - val_loss: 0.2539\n",
      "Epoch 231/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2544 - val_loss: 0.2539\n",
      "Epoch 232/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2543 - val_loss: 0.2538\n",
      "Epoch 233/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2543 - val_loss: 0.2537\n",
      "Epoch 234/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2542 - val_loss: 0.2537\n",
      "Epoch 235/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2541 - val_loss: 0.2536\n",
      "Epoch 236/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2541 - val_loss: 0.2536\n",
      "Epoch 237/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2540 - val_loss: 0.2535\n",
      "Epoch 238/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2540 - val_loss: 0.2535\n",
      "Epoch 239/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2539 - val_loss: 0.2534\n",
      "Epoch 240/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2539 - val_loss: 0.2533\n",
      "Epoch 241/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2538 - val_loss: 0.2533\n",
      "Epoch 242/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2538 - val_loss: 0.2532\n",
      "Epoch 243/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2537 - val_loss: 0.2532\n",
      "Epoch 244/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2536 - val_loss: 0.2531\n",
      "Epoch 245/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2536 - val_loss: 0.2531\n",
      "Epoch 246/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2535 - val_loss: 0.2530\n",
      "Epoch 247/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2535 - val_loss: 0.2529\n",
      "Epoch 248/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2534 - val_loss: 0.2529\n",
      "Epoch 249/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2534 - val_loss: 0.2528\n",
      "Epoch 250/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2533 - val_loss: 0.2528\n",
      "Epoch 251/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2532 - val_loss: 0.2527\n",
      "Epoch 252/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2532 - val_loss: 0.2526\n",
      "Epoch 253/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2531 - val_loss: 0.2526\n",
      "Epoch 254/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2531 - val_loss: 0.2525\n",
      "Epoch 255/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2530 - val_loss: 0.2524\n",
      "Epoch 256/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2530 - val_loss: 0.2524\n",
      "Epoch 257/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2529 - val_loss: 0.2523\n",
      "Epoch 258/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2528 - val_loss: 0.2523\n",
      "Epoch 259/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2528 - val_loss: 0.2522\n",
      "Epoch 260/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2527 - val_loss: 0.2521\n",
      "Epoch 261/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2527 - val_loss: 0.2521\n",
      "Epoch 262/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2526 - val_loss: 0.2520\n",
      "Epoch 263/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2525 - val_loss: 0.2520\n",
      "Epoch 264/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2525 - val_loss: 0.2519\n",
      "Epoch 265/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2524 - val_loss: 0.2518\n",
      "Epoch 266/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2524 - val_loss: 0.2518\n",
      "Epoch 267/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2523 - val_loss: 0.2517\n",
      "Epoch 268/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2522 - val_loss: 0.2516\n",
      "Epoch 269/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2522 - val_loss: 0.2516\n",
      "Epoch 270/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2521 - val_loss: 0.2515\n",
      "Epoch 271/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2521 - val_loss: 0.2515\n",
      "Epoch 272/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2520 - val_loss: 0.2514\n",
      "Epoch 273/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2519 - val_loss: 0.2513\n",
      "Epoch 274/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2519 - val_loss: 0.2513\n",
      "Epoch 275/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2518 - val_loss: 0.2512\n",
      "Epoch 276/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2517 - val_loss: 0.2511\n",
      "Epoch 277/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2517 - val_loss: 0.2511\n",
      "Epoch 278/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2516 - val_loss: 0.2510\n",
      "Epoch 279/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2516 - val_loss: 0.2509\n",
      "Epoch 280/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2515 - val_loss: 0.2509\n",
      "Epoch 281/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2514 - val_loss: 0.2508\n",
      "Epoch 282/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2514 - val_loss: 0.2507\n",
      "Epoch 283/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2513 - val_loss: 0.2507\n",
      "Epoch 284/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2513 - val_loss: 0.2506\n",
      "Epoch 285/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2512 - val_loss: 0.2506\n",
      "Epoch 286/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2511 - val_loss: 0.2505\n",
      "Epoch 287/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2511 - val_loss: 0.2504\n",
      "Epoch 288/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2510 - val_loss: 0.2504\n",
      "Epoch 289/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2509 - val_loss: 0.2503\n",
      "Epoch 290/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2509 - val_loss: 0.2502\n",
      "Epoch 291/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2508 - val_loss: 0.2502\n",
      "Epoch 292/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2508 - val_loss: 0.2501\n",
      "Epoch 293/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2507 - val_loss: 0.2500\n",
      "Epoch 294/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2506 - val_loss: 0.2500\n",
      "Epoch 295/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2506 - val_loss: 0.2499\n",
      "Epoch 296/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2505 - val_loss: 0.2499\n",
      "Epoch 297/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2505 - val_loss: 0.2498\n",
      "Epoch 298/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2504 - val_loss: 0.2497\n",
      "Epoch 299/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2503 - val_loss: 0.2497\n",
      "Epoch 300/300\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2503 - val_loss: 0.2496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff398262a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=300,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model we can use `predict` on the `autoencoder` fitted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now plot the results with the same code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
